---
title: "project_Hyperboria"
author: "Rémy CERDA and Valentin Lorentz"
date: "29 novembre 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
library("ggplot2")
library("dplyr")
```

# Produce data

On a computer connected to Hyperboria, create the file “scan_data.csv” with this content:

```
timestamp,round_start_timestamp,node,seq,nb_bytes,ttl,latency
```

Then, run:

* `python3 ping_scan.py` wait for the results, press Ctrl-C. This will produce `scan_data.csv`.
* `gzip scan_data.csv` (the result is in this git repo)
* `cat scan_data.csv.gz | gunzip | sed "s/ ms//" | gzip > scan_data_fixed.csv.gz`

And:

* `wget https://www.fc00.org/static/graph.json` (the result is in this git repo)
* `python3 compute_distances.py`. This will produce `node_distances.csv`.



# Load data

## Data structure

Each line is a ping sent to an Hyperboria node, using Debian's `ping`.

Columns are:

* timestamp: timestamp the ping was sent, as reported by ping.
* round_start_timestamp: timestamp the `ping` tool was invoked at.
* node: IPv6 address of the pinged node.
* seq: sequence number, as reported by ping. There is a bug with my script: for nodes that can be pinged, the seq is from 2 to 4, and for nodes which could not be reach it is from 0 to 2. The former should be fixed before analysing data.
* nb_bytes: number of bytes of the ICMP PING, as reported by ping
* ttl: ICMP TTL, as reported by ping
* latency: latency reported by ping.

```{r}
pings = read.csv("scan_data_fixed.csv.gz")
head(pings)
summary(pings)
```

## Fixes

Compensate offset bug of the ping collection script.

```{r}
lines_with_seq_offset = !is.na(pings$latency)
pings$seq[lines_with_seq_offset] = pings$seq[lines_with_seq_offset]-2
summary(pings$seq)
```

## Distances database

Load the database

```{r}
distances = read.csv("node_distances.csv")
```

Add distance column to the ping data:

```{r}
data = merge(pings, distances, by="node", all.x=TRUE)
head(data)
summary(data)
```


# Sample data

Take a sample for faster tests

```{r}
sampled_data = data[sample(nrow(data), 10000),]
```

# Analysis

## Latency distribution

First, let us have a look to the repartition of latency:
```{r}
summary(data$latency)
ggplot(data=data, aes(x=latency)) + xlim(0, 2000) + geom_histogram(binwidth=100);
```

## Latency and distance

```{r}
ggplot(data=data, aes(x=distance, y=latency)) + ylim(0, 2000) + geom_point();
```

```{r}
ggplot(data=data, aes(x=latency)) + xlim(0, 2000) + geom_histogram(binwidth=50) + facet_grid(distance ~ .);
```
```{r}
ggplot(data=data, aes(x=distance, y=latency)) + geom_boxplot();
```

## Lag graph of latency

```{r}
# too slow
# aggregated_data = aggregate(data, by=list(data$round_start_timestamp, data$node), FUN=mean)
aggregated_data = data[sampled_data$seq == 2,]
summary(aggregated_data$latency)
#df_lag = data.frame(old=c(data$latency)[1:length(c(data$latency))-1], new=c(data$latency)[2:length(c(data$latency))])

#library(data.table)
#df_lags = aggregated_data[, lag.latency:=c(NA, latency[-.N]), by=node]

#df_grouped = group_by(aggregated_data, node)
df_lag = aggregated_data %>% group_by(node) %>% mutate(latency_change=df_grouped$latency - dplyr::lag(df_grouped$latency))
#df_lag = aggregated_data %>% group_by(node) %>% mutate(latency_change=df_grouped$latency[1:length(df_grouped$latency)-1] - df_grouped$latency[2:df_grouped$latency])
head(df_lag)
summary(df_lag$old - df_lag$new)
ggplot(data=df_lag, aes(x=old, y=new)) + geom_point()
```
